{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyM5Yb1YteBVAgksyTTxvJ1p"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pwd\n",
    "!pip install torchmetrics"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaxBj-k2NC0m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1696867874889,
     "user_tz": -120,
     "elapsed": 6049,
     "user": {
      "displayName": "David Kostolani",
      "userId": "18304734719717997554"
     }
    },
    "outputId": "c41a0bd4-06ef-42be-b291-ca7c25c09d1c",
    "ExecuteTime": {
     "end_time": "2023-10-13T12:43:55.170981201Z",
     "start_time": "2023-10-13T12:43:53.235754467Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omco/Projects/Posao/A2P/IMU_Dataset\r\n",
      "Requirement already satisfied: torchmetrics in ./venv/lib/python3.8/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: numpy>1.20.0 in ./venv/lib/python3.8/site-packages (from torchmetrics) (1.24.4)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in ./venv/lib/python3.8/site-packages (from torchmetrics) (2.1.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./venv/lib/python3.8/site-packages (from torchmetrics) (0.9.0)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.8/site-packages (from torchmetrics) (4.8.0)\r\n",
      "Requirement already satisfied: packaging>=17.1 in ./venv/lib/python3.8/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (2023.9.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.8/site-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->torchmetrics) (12.2.140)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.8/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0RWeL0n5MWfh",
    "ExecuteTime": {
     "end_time": "2023-10-13T13:04:07.609709831Z",
     "start_time": "2023-10-13T13:03:57.503146862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting!\n",
      "Augmenting!\n",
      "Augmenting!\n",
      "Augmenting!\n",
      "reflect_imu_data!\n",
      "reflect_imu_data!\n",
      "Augmenting!\n",
      "Augmenting!\n",
      "Augmenting!\n",
      "Augmenting!\n",
      "reflect_imu_data!\n",
      "reflect_imu_data!\n",
      "Augmenting!\n",
      "reflect_imu_data!\n",
      "reflect_imu_data!\n",
      "Augmenting!\n",
      "Augmenting!\n",
      "reflect_imu_data!\n",
      "reflect_imu_data!\n",
      "Augmenting!\n",
      "reflect_imu_data!\n",
      "reflect_imu_data!\n",
      "Augmenting!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 56\u001B[0m\n\u001B[1;32m     53\u001B[0m val_prog \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ep \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, Epochs):\n\u001B[0;32m---> 56\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m iteration, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[1;32m     58\u001B[0m         net\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     60\u001B[0m         left_data \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/src/dataset.py:348\u001B[0m, in \u001B[0;36mIMUDatasetResample.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    345\u001B[0m resample_right \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresample_imu_data(croped_righ)\n\u001B[1;32m    347\u001B[0m labels_file \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(labels_path)\n\u001B[0;32m--> 348\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_annotations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    350\u001B[0m sem_labels, hand_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mannotate_IMU_data(resample_left, labels)\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# Apply augmentation with 50% probability if augment is True\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/src/dataset.py:218\u001B[0m, in \u001B[0;36mIMUDatasetResample.parse_annotations\u001B[0;34m(self, labels_df)\u001B[0m\n\u001B[1;32m    211\u001B[0m     sem_class \u001B[38;5;241m=\u001B[39m raw_label[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    212\u001B[0m     hand \u001B[38;5;241m=\u001B[39m raw_label[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    214\u001B[0m annotation_holder \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m: sem_class,\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhand\u001B[39m\u001B[38;5;124m'\u001B[39m: hand,\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfrom\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_sec(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecord In\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m3\u001B[39m:]),\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_sec(\u001B[43mlabels_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRecord In\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m3\u001B[39m:])}\n\u001B[1;32m    219\u001B[0m annotation_holder[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m annotation_holder[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m-\u001B[39m annotation_holder[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfrom\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    221\u001B[0m \u001B[38;5;66;03m#annotations = annotations.append(annotation_holder, ignore_index=True)\u001B[39;00m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;66;03m# annotations.loc[len(annotations)] = annotation_holder\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/pandas/core/series.py:1007\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1004\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[1;32m   1006\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[0;32m-> 1007\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1009\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[1;32m   1010\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[1;32m   1011\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1012\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/pandas/core/series.py:1116\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[0;34m(self, label, takeable)\u001B[0m\n\u001B[1;32m   1113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[1;32m   1115\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[0;32m-> 1116\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n\u001B[1;32m   1119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[loc]\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3651\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_loc\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   3626\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m \u001B[38;5;124;03m    Get integer location, slice or boolean mask for requested label.\u001B[39;00m\n\u001B[1;32m   3628\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3649\u001B[0m \u001B[38;5;124;03m    array([False,  True, False,  True])\u001B[39;00m\n\u001B[1;32m   3650\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3651\u001B[0m     casted_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_cast_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3652\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   3653\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n",
      "File \u001B[0;32m~/Projects/Posao/A2P/IMU_Dataset/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:6354\u001B[0m, in \u001B[0;36mIndex._maybe_cast_indexer\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   6350\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnd slice bound is non-scalar\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6352\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mslice\u001B[39m(start_slice, end_slice, step)\n\u001B[0;32m-> 6354\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_cast_indexer\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   6355\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   6356\u001B[0m \u001B[38;5;124;03m    If we have a float key and are not a floating index, then try to cast\u001B[39;00m\n\u001B[1;32m   6357\u001B[0m \u001B[38;5;124;03m    to an int if equivalent.\u001B[39;00m\n\u001B[1;32m   6358\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   6359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m key\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as dset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "\n",
    "from src.dataset import IMUDatasetResample\n",
    "from src.models import MS_TCN, MS_TCN2\n",
    "from src.models import focal_loss, tmse_loss\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "Epochs = 1000 #500  # 100\n",
    "\n",
    "Lr_Rate = 0.0001  # 0.001\n",
    "batch_size = 32 #256 #128  # 32 #4 8 16\n",
    "\n",
    "print_progress = 20\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "data_dir = './data/train'\n",
    "train_dataset = IMUDatasetResample(data_dir, freq=25, sample_len=10, augmentation=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dir = './data/validate/' # 'C:/Projects/01_A2P/HAR/06_Table_Dataset/annotated_IMUs/'\n",
    "val_dataset = IMUDatasetResample(data_dir, freq=25, sample_len=10)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# net = MS_TCN(num_stages=10, num_layers=4, num_f_maps=128, dim=12, num_classes=10)\n",
    "net = MS_TCN2(num_layers_PG=11, num_layers_R=10, num_R=4, num_f_maps=128, dim=12, num_classes=10)\n",
    "net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=Lr_Rate, weight_decay=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=Epochs//10, gamma=0.9)\n",
    "\n",
    "train_loss = list()\n",
    "train_acc = list()\n",
    "\n",
    "val_loss = list()\n",
    "val_acc = list()\n",
    "\n",
    "train_prog = 0\n",
    "val_prog = 0\n",
    "\n",
    "for ep in range(1, Epochs):\n",
    "    for iteration, data in enumerate(train_dataloader):\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        left_data = data[0].to(device)\n",
    "        right_data = data[1].to(device)\n",
    "        hands_data = torch.cat([left_data, right_data], dim=1)\n",
    "\n",
    "        labels = data[2].type(torch.long).to(device)\n",
    "\n",
    "        #hands = data[3]\n",
    "\n",
    "        outputs = net(hands_data)[-1]\n",
    "\n",
    "        loss = 0\n",
    "        splits = labels.shape[0]\n",
    "\n",
    "        for i, value in enumerate(outputs):\n",
    "            # loss += ce_loss(value.permute(1,0), labels[i])\n",
    "            loss += focal_loss(value.permute(1, 0), labels[i], num_class=10, alpha=-1, gamma=1)\n",
    "            loss += tmse_loss(value, labels[i], gamma=0.1)\n",
    "\n",
    "        loss = 10 * loss / splits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        train_prog += 1\n",
    "\n",
    "        acc = 0\n",
    "        for i, value in enumerate(outputs):\n",
    "            prob = F.softmax(value.permute(1, 0))\n",
    "            pred = prob.data.max(dim=1)[1]\n",
    "            # print()\n",
    "            # print(pred)\n",
    "            # print(labels[i])\n",
    "            # print(torchmetrics.functional.accuracy(pred, labels[i]).item())\n",
    "            acc += torchmetrics.functional.accuracy(pred, labels[i], task=\"multiclass\", num_classes=10).item()\n",
    "        train_acc.append(acc / splits)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_data = next(iter(val_dataloader))\n",
    "            net.eval()\n",
    "\n",
    "            left_data = data[0].to(device)\n",
    "            right_data = data[1].to(device)\n",
    "            hands_data = torch.cat([left_data, right_data], dim=1)\n",
    "\n",
    "            labels = data[2].type(torch.long).to(device)\n",
    "\n",
    "            outputs = net(hands_data)[-1]\n",
    "\n",
    "            loss_val = 0\n",
    "            splits = labels.shape[0]\n",
    "\n",
    "            for i, value in enumerate(outputs):\n",
    "                # loss_val += ce_loss(value.permute(1, 0), labels[i])\n",
    "                loss_val += focal_loss(value.permute(1, 0), labels[i], num_class=10, alpha=-1, gamma=1)\n",
    "                loss_val += tmse_loss(value, labels[i], gamma=0.1)\n",
    "\n",
    "            loss_val = 10 * loss_val / splits\n",
    "            val_prog += 1\n",
    "\n",
    "            acc_val = 0\n",
    "            for i, value in enumerate(outputs):\n",
    "                prob = F.softmax(value.permute(1, 0))\n",
    "                pred = prob.data.max(dim=1)[1]\n",
    "                acc_val += torchmetrics.functional.accuracy(pred, labels[i], task=\"multiclass\", num_classes=10).item()\n",
    "\n",
    "            for j in range(iteration + 1):\n",
    "                # len(dataset_split['train']) // len(dataset_split['test'])):  # same length of the lists...\n",
    "                val_loss.append(loss_val.item())\n",
    "                val_acc.append(acc_val / splits)\n",
    "\n",
    "        if ep % 1 == 0:\n",
    "            curr_t_loss = sum(train_loss[-train_prog:]) / train_prog\n",
    "            curr_t_acc = sum(train_acc[-train_prog:]) / train_prog\n",
    "            curr_v_loss = sum(val_loss[-val_prog:]) / val_prog\n",
    "            curr_v_acc = sum(val_acc[-val_prog:]) / val_prog\n",
    "            print(\n",
    "                '[%d/%d][%d/%d]\\tTraining Loss: %.4f \\tTraining Accuracy: %.4f \\tValidation Loss: %.4f \\tValidation Accuracy: %.4f'\n",
    "                % (\n",
    "                ep, Epochs, iteration, int(len(train_dataloader) / batch_size) + 1, curr_t_loss, curr_t_acc, curr_v_loss,\n",
    "                curr_v_acc))\n",
    "            train_prog = 0\n",
    "            val_prog = 0\n",
    "\n",
    "        if ep % 100 == 0:\n",
    "            net_path = './MS-TCN2_Vol1_e' + str(ep) + '.pt'\n",
    "            torch.save(net.state_dict(), net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omco/Projects/Posao/A2P/IMU_Dataset\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T13:06:50.480329784Z",
     "start_time": "2023-10-13T13:06:50.294947536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T12:43:58.900974847Z"
    }
   }
  }
 ]
}
